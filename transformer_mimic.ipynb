{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "transformer_mimic.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A28M2i0vnU-k",
        "cY0hso6pnU-o",
        "OEF9r7ljnU-s",
        "TIkIMZJ3nU-x",
        "wvqb3wHunU-0",
        "EXaAPEtTnU-4",
        "_l-iKTbxnU--",
        "xSiIYu3nnVAW"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhUfPHV8nU9w",
        "colab_type": "text"
      },
      "source": [
        "# Individual Project.\n",
        "Transformer on MIMIC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZr4-s0bnU9x",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6yNQArRnU9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "2e8931c9-26c8-4ce6-ab7a-fe1b90ae2046"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import TranslationDataset, Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0972e1c18cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHv4pDGqnU94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcb30GT8nU98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "74583ed0-d2a4-4ac8-fa33-1e232981a7d5"
      },
      "source": [
        "!spacy download en_core_web_sm\n",
        "!spacy link en_core_web_sm en\n",
        "\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\n",
            "\u001b[38;5;1m✘ Link 'en' already exists\u001b[0m\n",
            "To overwrite an existing link, use the --force flag\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEBm55fynU9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "num_reg_1 = r'\\d+\\.?\\d+|\\d'\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    res = []\n",
        "    for tok in spacy_en.tokenizer(text):\n",
        "        res.append(tok.text)\n",
        "        if len(res)>800:\n",
        "            break\n",
        "    return res\n",
        "num_token = '<num>'\n",
        "def tokenize_num(text):\n",
        "    res = []\n",
        "    for tok in spacy_en.tokenizer(text):\n",
        "        token = tok.text\n",
        "        num_res = re.search(num_reg_1,token)\n",
        "        if num_res is not None and num_res.span()[-1]-num_res.span()[0]==len(tok):\n",
        "                res.append(num_token)\n",
        "        else:\n",
        "            res.append(tok.text)\n",
        "        if len(res)>800:\n",
        "            break\n",
        "    return res"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LbOJ-0PnU-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "LABEL = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "LABEL_NUM = Field(tokenize = tokenize_num, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lm3sBKTVeTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "09b382ce-089b-4746-e2b5-b1cc931d57e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE1elqFfnU-Q",
        "colab_type": "text"
      },
      "source": [
        "We then load the MIMIC dataset and build the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ondA-SanU-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Field, Example, TabularDataset, BucketIterator\n",
        "fields = [('TEXT',None),('LABEL', LABEL), ('INPUT_TEXT', TEXT),('LABEL_NUM',LABEL_NUM)]\n",
        "train_data, valid_data,test_data = TabularDataset.splits(\n",
        "    path='/content/drive/My Drive/mimic/', format='csv',\n",
        "    train='train_data.csv',validation='val_data.csv', test='test_data.csv',\n",
        "    skip_header=True, fields=fields)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4uV72h9STUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uYY0OaanU-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq = 2)\n",
        "LABEL.build_vocab(train_data, min_freq = 2)\n",
        "LABEL_NUM.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TXMAZGuFi1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RJrnFHDnU-c",
        "colab_type": "text"
      },
      "source": [
        "Define the device and the data iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg583fjfnU-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-KZ_g0OnU-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_iterator,valid_iterator,test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data,test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort=False,\n",
        "     device = device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A28M2i0vnU-k",
        "colab_type": "text"
      },
      "source": [
        "## Building Transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kbsocdPnU-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 10000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHNl9UtSnU-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, src len]\n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7lGOggmnU-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3bl7n8nU-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry6-0oZOnU-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 10000\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, trg len]\n",
        "        #src_mask = [batch size, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "        #print('tok_embedding',self.tok_embedding(trg))\n",
        "        #print('pos_embedding',self.pos_embedding(pos))   \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-G--mXjnU-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, trg len]\n",
        "        #src_mask = [batch size, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx-0r1TYnU--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #print('enc_src size:',enc_src.shape)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnmOuDIanU_C",
        "colab_type": "text"
      },
      "source": [
        "## Training the Seq2Seq Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ro-DaZYnU_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "65adfefd-7b14-4757-9ade-cd66ff2c578e"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 4\n",
        "DEC_LAYERS = 4\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "print(INPUT_DIM)\n",
        "print(OUTPUT_DIM)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34495\n",
            "12822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itQUdhCLnU_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "TRG_PAD_IDX = LABEL.vocab.stoi[LABEL.pad_token]\n",
        "#TRG_PAD_IDX = LABEL_NUM.vocab.stoi[LABEL_NUM.pad_token]\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tP7wI5dnU_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a47044b7-d319-4a1e-c01f-df126a19178d"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 25,799,958 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu2LUFMGnU_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxbCEsw1nU_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwst5jVUnU_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhf3m9zJnU_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOnyrwkTnU_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.INPUT_TEXT\n",
        "        trg = batch.LABEL\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #print(src.shape)\n",
        "        #print(trg.shape)\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "        #print(output.shape)\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-B5CjcTnU_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.INPUT_TEXT\n",
        "            trg = batch.LABEL\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9WUJoXinU_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "def show_example(model):\n",
        "    example_idx = np.random.randint(len(valid_data))\n",
        "\n",
        "    src = vars(valid_data.examples[example_idx])['INPUT_TEXT']\n",
        "    trg = vars(valid_data.examples[example_idx])['LABEL'] \n",
        "\n",
        "    #print(f'src = {src}')\n",
        "    print('Reference:')\n",
        "\n",
        "    for tok in trg:\n",
        "        print(tok,end = ' ')\n",
        "    translation, attention = translate_sentence(src, TEXT, LABEL, model, device)\n",
        "    print()\n",
        "    print('prediction:')\n",
        "    num_mask = torch.zeros(len(translation))\n",
        "    for idx,tok in enumerate(translation):\n",
        "        print(tok,end = ' ')\n",
        "    #     num_res = re.search(num_reg_1,tok)\n",
        "    #     if num_res is not None and num_res.span()[-1]-num_res.span()[0]==len(tok):\n",
        "    #         num_mask[idx]=1\n",
        "    print()\n",
        "    # print(pred_mask)\n",
        "    # print(num_mask)\n",
        "    # print((pred_mask==num_mask))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueU67NIqnU_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "830e05db-cfa9-47b4-ab9c-1642c5d381c9"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    # show_example(model)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/mimic/transformer.pt')\n",
        "        #torch.save(model.state_dict(), '/content/drive/My Drive/mimic/transformer_test.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03041b5e6bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL98_Rny_oll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "a1b87fc7-e690-420b-b549-c4fe75c50dc2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(range(len(train_loss_list)),train_loss_list,label = 'train loss')\n",
        "plt.plot(range(len(valid_loss_list)),valid_loss_list,label = 'validation loss')\n",
        "plt.xlabel('epchos')\n",
        "plt.ylabel('Total loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/My Drive/mimic/tran_loss.png')\n",
        "plt.figure()\n",
        "plt.plot(range(len(train_gnt_loss_list)),train_gnt_loss_list,label = 'train generator loss')\n",
        "plt.plot(range(len(valid_gnt_loss_list)),valid_gnt_loss_list,label = 'validation generator loss')\n",
        "plt.xlabel('epchos')\n",
        "plt.ylabel('Generator loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/My Drive/mimic/generator_loss.png')\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(range(len(train_clf_loss_list)),train_clf_loss_list,label = 'train num loss')\n",
        "plt.plot(range(len(valid_clf_loss_list)),valid_clf_loss_list,label = 'validation num loss')\n",
        "plt.xlabel('epchos')\n",
        "plt.ylabel('Num loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/My Drive/mimic/num_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-35fb42dca872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/mimic/tran_loss.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gnt_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_gnt_loss_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train generator loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_gnt_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_gnt_loss_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation generator loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epchos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_gnt_loss_list' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pq-hGgIBYmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-m3CKCS_ot_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7mf9_SnnU_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd1ca31f-f8bb-4c6c-f915-194fbaf4e476"
      },
      "source": [
        "\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/mimic/transformer.pt'))\n",
        "# valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "# print(f'\\tValid Loss: {valid_loss:.3f} ')\n",
        "# test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "# print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUlRbPFfD69w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "492fde7b-07a1-4981-8260-69e78b14819a"
      },
      "source": [
        "pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5I9R2ysD6ES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b84715b9-c833-401a-d0d5-e01ccd7264a8"
      },
      "source": [
        "from rouge import Rouge\n",
        "import numpy as np\n",
        "\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougel_scores = []\n",
        "rouge = Rouge()\n",
        "for example_idx in range(len(valid_data.examples)):\n",
        "    src = vars(valid_data.examples[example_idx])['INPUT_TEXT']\n",
        "    trg = vars(valid_data.examples[example_idx])['LABEL']\n",
        "    translation, attention = translate_sentence(src, TEXT, LABEL, model, device)\n",
        "    reference = ' '.join(trg)\n",
        "    prediction = ' '.join(translation)\n",
        "    try:\n",
        "        scores = rouge.get_scores(prediction, reference)\n",
        "        rouge1_scores.append(scores[0]['rouge-1']['f'])\n",
        "        rouge2_scores.append(scores[0]['rouge-2']['f'])\n",
        "        rougel_scores.append(scores[0]['rouge-l']['f'])\n",
        "    except:\n",
        "        continue\n",
        "print('ROUGE-1 score:{},std: {},size:{}'.format(np.mean(np.array(rouge1_scores)),np.std(np.array(rouge1_scores)),len(rouge1_scores)))\n",
        "print('ROUGE-2 score:{},std: {},size:{}'.format(np.mean(np.array(rouge2_scores)),np.std(np.array(rouge2_scores)),len(rouge2_scores)))\n",
        "print('ROUGE-l score:{},std: {},size:{}'.format(np.mean(np.array(rougel_scores)),np.std(np.array(rougel_scores)),len(rougel_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROUGE-1 score:0.44446314127802006,std: 0.18854766659693092,size:4028\n",
            "ROUGE-2 score:0.32547978550272105,std: 0.17426743772941614,size:4028\n",
            "ROUGE-l score:0.4096124409393428,std: 0.18461686464667382,size:4028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6STyLzpHnU_r",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhpIXdzonU_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 2000):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAuYj2ognVAK",
        "colab_type": "text"
      },
      "source": [
        "Finally, we'll look at an example from the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-CQJwzwnVAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0dbd9928-4197-4a95-f6b5-71a077cb0ef6"
      },
      "source": [
        "example_idx = 500\n",
        "src = vars(test_data.examples[example_idx])['INPUT_TEXT']\n",
        "trg = vars(test_data.examples[example_idx])['LABEL']\n",
        "print(len(test_data.examples))\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3584\n",
            "src = [' ', 'the', 'patient', 'improved', 'once', 'intubated', 'and', 'treated', 'with', 'pht', '.', 'he', 'was', 'bridged', 'to', 'keppra', 'with', 'good', 'control', 'of', 'his', 'seizures', '.', 'a', 'cns', 'infection', 'was', 'ruled', 'out', 'and', 'antibiotics', 'were', 'withdrawn', ',', 'including', 'acyclovir', '.', 'he', 'has', 'remained', 'normothermic', 'with', 'stable', 'normal', 'wbc', 'values', '.', 'he', 'had', 'no', 'recurrent', 'seizures', '.', 'on', '09', '02', '08', 'he', 'fell', 'down', 'and', 'hit', 'his', 'head', 'without', 'loc', '.', 'a', 'ct', 'scan', 'ruled', 'out', 'new', 'hemorrhage', '.']\n",
            "trg = [' ', 'aspirin', '81', 'mg', 'tablet', ',', 'delayed', 'release', 'e.c.', 'sig', ':', 'one', '1', 'tablet', ',', 'delayed', 'release', 'e.c.', 'po', 'daily', 'daily', '.disp', ':', '30', 'tablet', ',', 'delayed', 'release', 'e.c.', 's', 'refills', ':', '0', 'latanoprost', '0.005', '%', 'drops', 'sig', ':', 'one', '1', 'drop', 'ophthalmic', 'hs', 'atbedtime', '.', 'timolol', 'maleate', '0.5', '%', 'drops', 'sig', ':', 'one', '1', 'drop', 'ophthalmicdaily', 'daily', '.', 'famotidine', '20', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'q12h', 'every', '12hours', '.disp', ':', '30', 'tablet', 's', 'refills', ':', '0', 'metoprolol', 'tartrate', '25', 'mg', 'tablet', 'sig', ':', '0.5', 'tablet', 'po', 'bid', '2times', 'a', 'day', '.disp', ':', '30', 'tablet', 's', 'refills', ':', '0', 'albuterol', 'sulfate', '2.5', 'mg', '3', 'ml', '0.083', '%', 'solution', 'fornebulization', 'sig', ':', 'one', '1', 'inhalation', 'q6h', 'every', '6', 'hours', 'asneeded', '.', 'ipratropium', 'bromide', '0.02', '%', 'solution', 'sig', ':', 'num', 'inhalation', 'q6h', 'every', '6', 'hours', 'as', 'needed', '.', 'simvastatin', '10', 'mg', 'tablet', 'sig', ':', 'two', '2', 'tablet', 'po', 'at', 'bedtime', '.', 'disp', ':', '60', 'tablet', 's', 'refills', ':', '0', 'warfarin', '4', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'at', 'bedtime', ':', 'onmonday', ',', 'wednesday', 'and', 'friday', '.', 'disp', ':', '30', 'tablet', 's', 'refills', ':', '0', 'coumadin', '5', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'at', 'bedtime', ':', 'ontuesday', ',', 'thursday', ',', 'saturday', 'and', 'sunday', '.', 'disp', ':', '30', 'tablet', 's', 'refills', ':', '0', 'outpatient', 'lab', 'workinr', 'follow', 'up', 'levetiracetam', '750', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'twice', 'aday', '.', 'disp', ':', '60', 'tablet', 's', 'refills', ':', '0']\n",
            "[41, 71, 92, 8, 5, 15, 27, 21, 28, 7, 4, 11, 9, 5, 15, 27, 21, 28, 10, 12, 12, 35, 4, 34, 5, 15, 27, 21, 28, 19, 17, 4, 30, 538, 525, 55, 215, 7, 4, 11, 9, 276, 217, 81, 141, 6, 567, 422, 74, 55, 215, 7, 4, 11, 9, 276, 1412, 12, 6, 283, 43, 8, 5, 7, 4, 11, 9, 5, 10, 104, 24, 411, 35, 4, 34, 5, 19, 17, 4, 30, 75, 86, 67, 8, 5, 7, 4, 74, 5, 10, 32, 58, 16, 14, 35, 4, 34, 5, 19, 17, 4, 30, 102, 97, 113, 8, 40, 26, 197, 55, 48, 267, 7, 4, 11, 9, 79, 65, 24, 44, 25, 137, 6, 150, 147, 234, 55, 48, 7, 4, 84, 79, 65, 24, 44, 25, 22, 23, 6, 157, 39, 8, 5, 7, 4, 38, 13, 5, 10, 63, 76, 6, 31, 4, 46, 5, 19, 17, 4, 30, 144, 42, 8, 5, 7, 4, 11, 9, 5, 10, 63, 76, 4, 4151, 15, 467, 91, 432, 6, 31, 4, 34, 5, 19, 17, 4, 30, 294, 33, 8, 5, 7, 4, 11, 9, 5, 10, 63, 76, 4, 4573, 15, 803, 15, 966, 91, 955, 6, 31, 4, 34, 5, 19, 17, 4, 30, 177, 204, 983, 456, 472, 308, 408, 8, 5, 7, 4, 11, 9, 5, 10, 73, 51, 6, 31, 4, 46, 5, 19, 17, 4, 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0GqkNL5nVAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "97799da8-15b1-4513-e1fd-dc3a86ebe504"
      },
      "source": [
        "translation, attention = translate_sentence(src, TEXT, LABEL, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "reference = ' '.join(trg)\n",
        "prediction = ' '.join(translation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = [' ', 'aspirin', '81', 'mg', 'tablet', ',', 'chewable', 'sig', ':', 'one', '1', 'tablet', ',', 'chewablepo', 'daily', 'daily', '.', 'atorvastatin', '10', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'daily', 'daily', '.', 'metoprolol', 'tartrate', '25', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'bid', '2', 'times', 'a', 'day', '.', 'lisinopril', '10', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'daily', 'daily', '.', 'furosemide', '40', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'daily', 'daily', '.', 'warfarin', '2', 'mg', 'tablet', 'sig', ':', 'one', '1', 'tablet', 'po', 'once', 'daily', 'at', '4pm', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyWuSqccgZEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "dac19130-2365-46c4-be56-6adb26cc9718"
      },
      "source": [
        "pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bka0d0vWA-nv",
        "colab_type": "text"
      },
      "source": [
        "Compute ROUGE score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jOgyIaajBsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "54477918-a8d9-40d0-964b-ff68f576b13b"
      },
      "source": [
        "from rouge import Rouge\n",
        "import numpy as np\n",
        "\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougel_scores = []\n",
        "rouge = Rouge()\n",
        "for example_idx in range(len(test_data.examples)):\n",
        "    src = vars(test_data.examples[example_idx])['INPUT_TEXT']\n",
        "    trg = vars(test_data.examples[example_idx])['LABEL']\n",
        "    translation, attention = translate_sentence(src, TEXT, LABEL, model, device)\n",
        "    reference = ' '.join(trg)\n",
        "    prediction = ' '.join(translation)\n",
        "    try:\n",
        "        scores = rouge.get_scores(prediction, reference)\n",
        "        rouge1_scores.append(scores[0]['rouge-1']['f'])\n",
        "        rouge2_scores.append(scores[0]['rouge-2']['f'])\n",
        "        rougel_scores.append(scores[0]['rouge-l']['f'])\n",
        "    except:\n",
        "        continue\n",
        "print('ROUGE-1 score:{}'.format(np.mean(np.array(rouge1_scores))))\n",
        "print('ROUGE-2 score:{}'.format(np.mean(np.array(rouge2_scores))))\n",
        "print('ROUGE-l score:{}'.format(np.mean(np.array(rougel_scores))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROUGE-1 score:0.449367195570384\n",
            "ROUGE-2 score:0.32831988306890353\n",
            "ROUGE-l score:0.4135474939827097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhwitKBZRQAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0186a5a1-bd9c-4afb-86ee-63bb2408dbfe"
      },
      "source": [
        "pip install word2number"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting word2number\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5587 sha256=4c8a7cca26a0b8ab45969b24af5b0775bc2dae629118272fd36aa234ef2cb71f\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olL_LHj_BKdO",
        "colab_type": "text"
      },
      "source": [
        "Compute Number Recall/Precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bB70rUJUqJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_split(text):\n",
        "    return text.split(' ')\n",
        "def number_recall(pre,ref,n=4,threshold=0.7):\n",
        "    prediction = pre\n",
        "    reference = ref\n",
        "    pre_num = []\n",
        "    ref_num = []\n",
        "    pre_toks = tokenize_split(prediction)\n",
        "    ref_toks = tokenize_split(reference)\n",
        "    pre_nums_count = 0\n",
        "    ref_nums_count = 0\n",
        "    # extract numbers in prediction\n",
        "    for idx,tok in enumerate(pre_toks):\n",
        "        numbers = re.findall(r'\\d+[\\,\\d+]{1,}|\\d+\\.?\\d+|\\d+',tok)\n",
        "        if(len(numbers)!=0):\n",
        "            pre_nums_count += 1\n",
        "            pre_num.append((numbers[0],idx))\n",
        "        \n",
        "    # extract numbers in reference\n",
        "    for idx,tok in enumerate(ref_toks):\n",
        "        numbers = re.findall(r'\\d+[\\,\\d+]{1,}|\\d+\\.?\\d+|\\d+',tok)\n",
        "        if(len(numbers)!=0):\n",
        "            ref_nums_count += 1\n",
        "            ref_num.append((numbers[0],idx))      \n",
        "#     print('numbers in reference:{}'.format(ref_num))\n",
        "#     print('')\n",
        "#     print('numbers in prediction:{}'.format(pre_num))\n",
        "    rec_num_count = 0\n",
        "    rec_nums = []\n",
        "    for r_num,r_idx in (ref_num):\n",
        "        for p_num,p_idx in pre_num:\n",
        "            if r_num == p_num:\n",
        "                ref_info = []\n",
        "                pre_info = []\n",
        "                ref_info.append(ref_toks[r_idx])\n",
        "                pre_info.append(pre_toks[p_idx])\n",
        "                #提取两边的token\n",
        "                n_gram = 1\n",
        "                while n_gram<n+1 and r_idx-n_gram>=0 and p_idx-n_gram>=0:\n",
        "                    ref_info.insert(0,ref_toks[r_idx-n_gram])\n",
        "                    pre_info.insert(0,pre_toks[p_idx-n_gram])\n",
        "                    n_gram += 1\n",
        "                n_gram = 1\n",
        "                while n_gram<n+1 and r_idx+n_gram<len(ref_toks) and p_idx+n_gram<len(pre_toks):\n",
        "                    ref_info.append(ref_toks[r_idx+n_gram])\n",
        "                    pre_info.append(pre_toks[p_idx+n_gram])\n",
        "                    n_gram += 1\n",
        "                if len(ref_info)==0 or len(pre_info)==0:\n",
        "                    continue\n",
        "                # tokens -> sentence\n",
        "                rs = ' '.join(ref_info)\n",
        "                ps = ' '.join(pre_info)\n",
        "                # compute rouge scores and use f1 measure \n",
        "                rouge = Rouge()\n",
        "                scores = rouge.get_scores(ps, rs)\n",
        "                rg_f = 0\n",
        "                for keys in scores[0]:\n",
        "                    rg_f += scores[0][keys]['f']\n",
        "                if rg_f/3>threshold:\n",
        "                    rec_num_count += 1\n",
        "                    rec_nums.append(r_num)\n",
        "                    \n",
        "                    break\n",
        "    if ref_nums_count==0:\n",
        "        rec_rate = False\n",
        "    else:\n",
        "        rec_rate = rec_num_count/ref_nums_count\n",
        "    if pre_nums_count==0:\n",
        "        pre_rate = False\n",
        "    else:\n",
        "        pre_rate = rec_num_count/pre_nums_count\n",
        "    return rec_rate,pre_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94ATfQndU14e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e18dced0-6422-41eb-d532-647b3dbb35b2"
      },
      "source": [
        "from rouge import Rouge\n",
        "import numpy as np\n",
        "num_rec_scores = []\n",
        "num_pre_scores = []\n",
        "rouge = Rouge()\n",
        "for example_idx in range(len(valid_data.examples)):\n",
        "    src = vars(valid_data.examples[example_idx])['INPUT_TEXT']\n",
        "    trg = vars(valid_data.examples[example_idx])['LABEL']\n",
        "    translation, attention = translate_sentence(src, TEXT, LABEL, model, device)\n",
        "    reference = ' '.join(trg)\n",
        "    prediction = ' '.join(translation)\n",
        "    # try:\n",
        "    #     scores = number_recall(prediction,reference)\n",
        "    #     if scores is False:\n",
        "    #         continue\n",
        "    #     num_rec_scores.append(scores)\n",
        "    # except:\n",
        "    #     continue\n",
        "    scores,pre= number_recall(prediction,reference)\n",
        "    if scores is False:\n",
        "        a=1\n",
        "    else:\n",
        "        num_rec_scores.append(scores)\n",
        "    if pre is False:\n",
        "        a=1\n",
        "    else:\n",
        "        num_pre_scores.append(pre)\n",
        "print('Number recall score:{}'.format(np.mean(np.array(num_rec_scores))))\n",
        "print('Number recall score std:{}'.format(np.std(np.array(num_rec_scores))))\n",
        "print('Number precision score:{}'.format(np.mean(np.array(num_pre_scores))))\n",
        "print('Number precision score std:{}'.format(np.std(np.array(num_pre_scores))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number recall score:0.2097649644880073\n",
            "Number recall score std:0.16706367579015793\n",
            "Number precision score:0.3504134840981854\n",
            "Number precision score std:0.2781752191896118\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}